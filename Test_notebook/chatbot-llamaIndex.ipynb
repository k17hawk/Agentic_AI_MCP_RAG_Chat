{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1de78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfb29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92b24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage,MessageRole\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f702a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(\n",
    "    model = 'llama-3.3-70b-versatile',\n",
    "    temperature = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59beb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    history = [\n",
    "        ChatMessage(role=MessageRole.SYSTEM,content = \"You are an expert Chatbot assistant, Be consise and accurate\")\n",
    "    ]\n",
    "    print(\"LLama-index chatbot. Type 'exit' to quite \\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() in {\"exit\",'quite'}:\n",
    "            break\n",
    "        history.append(ChatMessage(role=MessageRole.USER, content=user_input))\n",
    "\n",
    "        response = llm.chat(messages = history)\n",
    "        answer = response.message.content\n",
    "        print(f\"LLama-3 Bot: {answer} \\n\")\n",
    "        history.append(ChatMessage(role=MessageRole.ASSISTANT,content=answer))\n",
    "        print(\"-\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb521ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLama-index chatbot. Type 'exit' to quite \n",
      "\n",
      "LLama-3 Bot: **User Location in Recommendation Systems: A Geospatial Perspective**\n",
      "\n",
      "In the context of recommendation systems, user location refers to the geographical position of a user, which can be utilized to enhance the accuracy and relevance of recommendations. The incorporation of user location into recommendation systems is based on the notion that a user's physical location can significantly influence their preferences, behaviors, and interests.\n",
      "\n",
      "**Types of Location-Based Recommendation Systems:**\n",
      "\n",
      "1. **Geographic-based recommendation systems**: These systems recommend items based on the user's current location, such as nearby restaurants, shops, or points of interest.\n",
      "2. **Location-aware recommendation systems**: These systems consider the user's location history and preferences to provide recommendations that are tailored to their specific needs and interests.\n",
      "3. **Geo-social recommendation systems**: These systems integrate social network analysis with geographic information to recommend items based on the user's social connections and location.\n",
      "\n",
      "**Key Challenges:**\n",
      "\n",
      "1. **Location data collection and processing**: Collecting and processing location data can be challenging due to issues such as data quality, scalability, and privacy concerns.\n",
      "2. **Location-based cold start problem**: New users or items may not have sufficient location-based data, making it difficult to provide accurate recommendations.\n",
      "3. **Location-based context awareness**: Recommendation systems need to be aware of the user's current context, including their location, time, and activity, to provide relevant recommendations.\n",
      "\n",
      "**State-of-the-Art Methods:**\n",
      "\n",
      "1. **Collaborative filtering with location-based matrix factorization**: This approach integrates location-based information into traditional collaborative filtering methods to improve recommendation accuracy.\n",
      "2. **Deep learning-based methods**: Techniques such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs) can be used to model complex location-based relationships and provide personalized recommendations.\n",
      "3. **Hybrid approaches**: Combining multiple techniques, such as content-based filtering, collaborative filtering, and location-based methods, can lead to more accurate and diverse recommendations.\n",
      "\n",
      "**Evaluation Metrics:**\n",
      "\n",
      "1. **Precision**: The ratio of relevant recommended items to the total number of recommended items.\n",
      "2. **Recall**: The ratio of relevant recommended items to the total number of relevant items.\n",
      "3. **F1-score**: The harmonic mean of precision and recall.\n",
      "4. **Mean Average Precision (MAP)**: The average precision at each recall level.\n",
      "\n",
      "**Real-World Applications:**\n",
      "\n",
      "1. **Location-based advertising**: Recommendation systems can be used to deliver targeted advertisements to users based on their location and interests.\n",
      "2. **Tourism and travel recommendation**: Systems can recommend destinations, attractions, and activities based on a user's location and preferences.\n",
      "3. **Food delivery and restaurant recommendation**: Recommendation systems can suggest restaurants and food options based on a user's location and culinary preferences.\n",
      "\n",
      "In conclusion, user location is a crucial factor in recommendation systems, as it can significantly enhance the accuracy and relevance of recommendations. By incorporating location-based information and leveraging state-of-the-art methods, recommendation systems can provide more personalized and effective recommendations to users. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LLama-3 Bot: **Enhancing Recommendation Systems with Reinforcement Learning**\n",
      "\n",
      "Reinforcement learning (RL) can significantly enhance recommendation systems by allowing them to learn from user interactions and adapt to changing user preferences. Here's how RL can improve recommendation systems:\n",
      "\n",
      "**Key Benefits:**\n",
      "\n",
      "1. **Personalization**: RL can learn to personalize recommendations for individual users based on their unique preferences and behavior.\n",
      "2. **Exploration-Exploitation Trade-off**: RL can balance the trade-off between exploring new items and exploiting known user preferences to maximize user engagement.\n",
      "3. **Dynamic Adaptation**: RL can adapt to changing user preferences and behavior over time, ensuring that recommendations remain relevant and effective.\n",
      "\n",
      "**RL Algorithms for Recommendation Systems:**\n",
      "\n",
      "1. **Deep Q-Networks (DQN)**: DQN can be used to learn a Q-function that estimates the expected return of recommending an item to a user.\n",
      "2. **Policy Gradient Methods**: Policy gradient methods, such as REINFORCE, can be used to learn a policy that recommends items to users based on their preferences.\n",
      "3. **Actor-Critic Methods**: Actor-critic methods, such as Deep Deterministic Policy Gradient (DDPG), can be used to learn both a policy and a value function to recommend items to users.\n",
      "\n",
      "**Example Applications:**\n",
      "\n",
      "1. **Movie Recommendation**: A movie streaming service can use RL to recommend movies to users based on their watching history and ratings. The RL algorithm can learn to balance the trade-off between recommending popular movies and exploring new movies that the user may enjoy.\n",
      "2. **Product Recommendation**: An e-commerce platform can use RL to recommend products to users based on their browsing and purchasing history. The RL algorithm can learn to adapt to changing user preferences and behavior over time.\n",
      "3. **Music Recommendation**: A music streaming service can use RL to recommend songs to users based on their listening history and ratings. The RL algorithm can learn to balance the trade-off between recommending popular songs and exploring new songs that the user may enjoy.\n",
      "\n",
      "**Example Code (PyTorch):**\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "\n",
      "class RecommendationEnvironment:\n",
      "    def __init__(self, user_embeddings, item_embeddings):\n",
      "        self.user_embeddings = user_embeddings\n",
      "        self.item_embeddings = item_embeddings\n",
      "\n",
      "    def step(self, user_id, item_id):\n",
      "        # Calculate the reward based on the user's interaction with the item\n",
      "        reward = self.calculate_reward(user_id, item_id)\n",
      "        # Update the user's embedding based on the interaction\n",
      "        self.user_embeddings[user_id] = self.update_user_embedding(user_id, item_id)\n",
      "        return reward, self.user_embeddings[user_id]\n",
      "\n",
      "class DQN(nn.Module):\n",
      "    def __init__(self, state_dim, action_dim):\n",
      "        super(DQN, self).__init__()\n",
      "        self.fc1 = nn.Linear(state_dim, 128)\n",
      "        self.fc2 = nn.Linear(128, 128)\n",
      "        self.fc3 = nn.Linear(128, action_dim)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = torch.relu(self.fc1(x))\n",
      "        x = torch.relu(self.fc2(x))\n",
      "        x = self.fc3(x)\n",
      "        return x\n",
      "\n",
      "# Initialize the environment and the DQN\n",
      "env = RecommendationEnvironment(user_embeddings, item_embeddings)\n",
      "dqn = DQN(state_dim=128, action_dim=10)\n",
      "\n",
      "# Train the DQN using Q-learning\n",
      "for episode in range(1000):\n",
      "    user_id = np.random.randint(0, 100)\n",
      "    item_id = np.random.randint(0, 10)\n",
      "    state = env.user_embeddings[user_id]\n",
      "    action = dqn(state)\n",
      "    reward, next_state = env.step(user_id, item_id)\n",
      "    # Update the DQN using Q-learning\n",
      "    loss = (reward + 0.9 * dqn(next_state) - dqn(state)) ** 2\n",
      "    optimizer = optim.Adam(dqn.parameters(), lr=0.001)\n",
      "    optimizer.zero_grad()\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "```\n",
      "In this example, the `RecommendationEnvironment` class simulates a recommendation environment where users interact with items. The `DQN` class implements a deep Q-network that learns to recommend items to users based on their preferences. The `train` loop trains the DQN using Q-learning to maximize the cumulative reward.\n",
      "\n",
      "**Real-World Applications:**\n",
      "\n",
      "1. **Netflix**: Netflix uses RL to recommend TV shows and movies to users based on their watching history and ratings.\n",
      "2. **Amazon**: Amazon uses RL to recommend products to users based on their browsing and purchasing history.\n",
      "3. **Spotify**: Spotify uses RL to recommend songs to users based on their listening history and ratings.\n",
      "\n",
      "By leveraging RL algorithms, recommendation systems can learn to adapt to changing user preferences and behavior, providing more personalized and effective recommendations. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LLama-3 Bot: How can I assist you today? Do you have any questions or topics you'd like to discuss, perhaps related to recommendation systems or reinforcement learning? \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815c094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
