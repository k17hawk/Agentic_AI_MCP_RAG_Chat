{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67141a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126fe747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c434d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4209aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4697db70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e452eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a2b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model = \"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cdee7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser  = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_flow():\n",
    "    chat_history = [\n",
    "        (\"system\",\" You are helpful chatbot assistant, be excited, concise and accurate.\")\n",
    "    ]\n",
    "    print(\"Langchain Chatbot, Type 'exit' to quite \\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        #add user messages to chat history \n",
    "        chat_history.append(('user',user_input))\n",
    "\n",
    "        #prompt using ChatPromptTemplate\n",
    "        prompt = ChatPromptTemplate.from_messages(chat_history)\n",
    "        chain = prompt | llm | parser\n",
    "        #get the response from query \n",
    "        response = chain.invoke({})\n",
    "        #display the response\n",
    "        print(f\"LLama-3: {response} \\n\")\n",
    "        #saving the chat in history\n",
    "        chat_history.append(('assistant',response))\n",
    "        print(\"**\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain Chatbot. Type 'exit' to quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d5589ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain Chatbot, Type 'exit' to quite \n",
      "\n",
      "LLama-3: I'm doing great, thanks for asking. I'm ready to help with any questions or tasks you have, so what's on your mind? \n",
      "\n",
      "********************************************************************************************************************************************************************************************************\n",
      "LLama-3: It looks like you didn't type anything. Feel free to ask me a question or share what's on your mind, and I'll do my best to help! \n",
      "\n",
      "********************************************************************************************************************************************************************************************************\n",
      "LLama-3: User location plays a significant role in recommendation and ranking systems, especially in applications that involve:\n",
      "\n",
      "1. **Geographic relevance**: Location-based services like food delivery, ride-hailing, or hotel booking, where nearby options are prioritized.\n",
      "2. **Local preferences**: Recommendations for restaurants, events, or activities that are popular in a specific area.\n",
      "3. **Language and cultural differences**: Location influences language, cultural, and content preferences, which can be factored into recommendations.\n",
      "4. **Proximity-based ranking**: Search results, such as nearby stores or services, are ranked based on their distance from the user's location.\n",
      "\n",
      "To incorporate user location, recommendation systems use techniques like:\n",
      "\n",
      "1. **Geospatial indexing**: Efficiently storing and querying location-based data.\n",
      "2. **Location-based filtering**: Filtering out irrelevant results based on distance or geographic boundaries.\n",
      "3. **Context-aware modeling**: Using location as a feature to improve model accuracy and relevance.\n",
      "4. **Personalization**: Combining location data with user behavior and preferences to provide tailored recommendations.\n",
      "\n",
      "Some popular algorithms that utilize user location include:\n",
      "\n",
      "1. **K-Nearest Neighbors (KNN)**: Finds nearby users or items based on location.\n",
      "2. **Geographic Information Systems (GIS)**: Analyzes and visualizes geospatial data to inform recommendations.\n",
      "3. **Location-based Collaborative Filtering**: Recommends items based on the behavior of nearby users.\n",
      "\n",
      "By considering user location, recommendation and ranking systems can provide more accurate, relevant, and personalized results, enhancing the overall user experience. \n",
      "\n",
      "********************************************************************************************************************************************************************************************************\n",
      "LLama-3: If user location is not present in the data, like in Yelp, recommendation systems can still utilize other signals to provide relevant results. Here are some strategies:\n",
      "\n",
      "1. **IP address-based location inference**: Yelp can use IP address geolocation to estimate the user's location, although this method may not be highly accurate.\n",
      "2. **Search query analysis**: Analyze the user's search query to infer their location. For example, if a user searches for \"restaurants in San Francisco,\" Yelp can assume they are interested in San Francisco-based results.\n",
      "3. **User review history**: If a user has reviewed businesses in a specific location, Yelp can infer that they are likely to be interested in similar locations.\n",
      "4. **Business category and keyword filtering**: Filter search results based on business categories and keywords, which can help provide relevant results even without location data.\n",
      "5. **Default to popular or highly-rated results**: In the absence of location data, Yelp can default to showing popular or highly-rated businesses, which are likely to be of interest to a wide range of users.\n",
      "6. **Ask users for location**: Yelp can prompt users to provide their location or allow them to set a default location, which can be used to provide more accurate results.\n",
      "7. **Use external data sources**: Yelp can use external data sources, such as the user's social media profiles or other online activity, to infer their location.\n",
      "\n",
      "Some algorithms that can be used in the absence of user location data include:\n",
      "\n",
      "1. **Content-based filtering**: Recommends businesses based on their attributes, such as category, rating, or keywords.\n",
      "2. **Collaborative filtering**: Recommends businesses based on the behavior of similar users, without considering location.\n",
      "3. **Matrix factorization**: Reduces the dimensionality of the user-business interaction matrix to provide recommendations.\n",
      "4. **Graph-based methods**: Models the relationships between businesses and users as a graph, and provides recommendations based on graph-based algorithms.\n",
      "\n",
      "While these strategies can help provide relevant results, they may not be as accurate as location-based recommendations. If user location data is available, it can significantly improve the accuracy and relevance of recommendations. \n",
      "\n",
      "********************************************************************************************************************************************************************************************************\n",
      "LLama-3: It seems like you didn't type anything. If you're ready to ask a question or need help with something, feel free to ask, and I'll do my best to assist you! \n",
      "\n",
      "********************************************************************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "chat_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53b367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
